{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Binary vs. Multi-Class Classification<br>\n",
    "\n",
    "Task 1:<br>\n",
    "Binary Classification: Predict if a website visitor will click a button (Click or No Click).<br>\n",
    "Use a web visitor interaction dataset.<br>\n",
    "Task: Implement binary classification for click prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8233\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Click       0.83      0.91      0.87       191\n",
      "       Click       0.81      0.67      0.73       109\n",
      "\n",
      "    accuracy                           0.82       300\n",
      "   macro avg       0.82      0.79      0.80       300\n",
      "weighted avg       0.82      0.82      0.82       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 1: Create synthetic dataset simulating website visitor interactions\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Features (example): time_on_site (seconds), pages_visited, referral_source (0=direct,1=search,2=ad)\n",
    "time_on_site = np.random.exponential(scale=100, size=n_samples)  # time spent on site\n",
    "pages_visited = np.random.poisson(lam=5, size=n_samples)        # number of pages visited\n",
    "referral_source = np.random.choice([0,1,2], size=n_samples, p=[0.5, 0.3, 0.2])\n",
    "\n",
    "# Target: whether user clicked the button (1) or not (0)\n",
    "# Assume people with longer time, more pages, and ad referral more likely to click\n",
    "click_prob = (\n",
    "    0.02 * time_on_site +\n",
    "    0.1 * pages_visited +\n",
    "    0.15 * (referral_source == 2).astype(int)\n",
    ")\n",
    "click_prob = 1 / (1 + np.exp(- (click_prob - 3)))  # sigmoid to convert to probability\n",
    "\n",
    "clicked = np.random.binomial(1, click_prob)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'time_on_site': time_on_site,\n",
    "    'pages_visited': pages_visited,\n",
    "    'referral_source': referral_source,\n",
    "    'clicked': clicked\n",
    "})\n",
    "\n",
    "# Step 2: Preprocess data\n",
    "X = df.drop('clicked', axis=1)\n",
    "y = df['clicked']\n",
    "\n",
    "# One-hot encode referral_source categorical variable\n",
    "X = pd.get_dummies(X, columns=['referral_source'], drop_first=True)\n",
    "\n",
    "# Step 3: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Step 4: Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 5: Train logistic regression classifier\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 6: Predict and evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Click', 'Click']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2:<br>\n",
    "Multi-Class Classification: Recognize handwritten digits (0-9).<br>\n",
    "Use the MNIST dataset.<br>\n",
    "Task: Develop a model that correctly classifies each handwritten digit.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9815\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        54\n",
      "           1       0.95      0.95      0.95        55\n",
      "           2       1.00      1.00      1.00        53\n",
      "           3       1.00      1.00      1.00        55\n",
      "           4       0.98      0.98      0.98        54\n",
      "           5       1.00      0.98      0.99        55\n",
      "           6       1.00      0.98      0.99        54\n",
      "           7       1.00      1.00      1.00        54\n",
      "           8       0.91      0.94      0.92        52\n",
      "           9       0.98      0.98      0.98        54\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load MNIST-like digits dataset (8x8 images)\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data       # 64 features (8x8 pixel intensities)\n",
    "y = digits.target     # Labels: digits 0-9\n",
    "\n",
    "# Split data into train and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression for multi-class classification (default 'ovr' or 'multinomial')\n",
    "model = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3:<br>\n",
    "Multi-Class Classification: Classify a flower species based on petal and sepal measurements.<br>\n",
    "Use the Iris dataset.<br>\n",
    "Task: Use features to classify into three species: Setosa, Versicolor, or Virginica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       1.00      0.80      0.89        15\n",
      "   virginica       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data        # Features: sepal length, sepal width, petal length, petal width\n",
    "y = iris.target      # Target: species (0=setosa, 1=versicolor, 2=virginica)\n",
    "\n",
    "# Split dataset into train and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
